# Visual Archive Explorer ğŸ”

**A Semantic Visual Search Engine for Digital Art Discovery**

This tool implements a **content-based image retrieval (CBIR)** system designed to help users navigate vast digital archives. Instead of relying on text keywords, the system uses **Computer Vision** to understand the stylistic and semantic content of an image, allowing for a "visual-to-visual" search experience.

### ğŸš€ Key Features
* **Visual Querying:** Upload an image to find stylistically similar artworks, sketches, or photographs.
* **Zero-Shot Learning:** Powered by **OpenAI's CLIP** model, enabling the system to understand image concepts without manual labeling.
* **Fast Indexing:** Utilizes **FAISS** for millisecond-latency retrieval from large datasets.
* **Interactive Agent:** Includes a conversational AI interface that acts as a digital historian, analyzing and explaining visual connections.

### ğŸ› ï¸ Technical Architecture
The system follows a two-stage retrieval pipeline:
1.  **Offline Vectorization:** The `archive_builder.py` script scans the dataset and converts images into 512-dimensional vector embeddings.
2.  **Real-Time Inference:** The `run_chatbot.py` application computes Cosine Similarity between the user's input and the stored archive index.

---

### ğŸ“‹ How to Run (The Bulletproof Method)

**âš ï¸ Important:** This project requires **Anaconda** or **Miniconda** to run correctly, especially on Mac (M1/M2/M3) to avoid segmentation faults.

#### 1. Set up the Environment
Open your terminal and run these commands exactly in order. We use Python 3.10 because newer versions (3.13) do not support FAISS yet.

```bash
# 1. Create the environment
conda create -n art_bot python=3.10 -y
```

# 2. Activate the environment (Do this every time you open a terminal)
```
conda activate art_bot
```

# 3. Install FAISS using Conda (Fixes Mac crashes)
```
conda install -c pytorch faiss-cpu -y
```

# 4. Install the remaining AI libraries via Pip
```
pip install streamlit torch transformers Pillow numpy requests
```

## 2. Generate Dataset
Downloads 500 sample images from the Lorem Picsum API to create your digital museum.
```
python download_images.py
```
(Wait until it says: "âœ… Download Complete!")

3. Build Index
Scans the images, converts them to mathematical vectors, and saves the database.
```
python archive_builder.py
```
(Wait until it says: "--- Done! Database built successfully. ---")

4. Launch Interface
Starts the web interface where you can upload images.
```
streamlit run run_chatbot.py
```

## Project structure 
```
visual_archive_bot/
â”‚
â”œâ”€â”€ archive_builder.py       # (Step 2: Scans images & builds the FAISS index)
â”œâ”€â”€ chatbot_base.py          # (Parent class for the chatbot)
â”œâ”€â”€ download_images.py       # (Step 1: Downloads sample art dataset)
â”œâ”€â”€ README.md                # (Documentation)
â”œâ”€â”€ requirements.txt         # (List of libraries)
â”œâ”€â”€ run_chatbot.py           # (Step 3: The main Streamlit app to run)
â”œâ”€â”€ visual_archive_bot.py    # (The logic class inheriting from ChatbotBase)
â”‚
â”œâ”€â”€ images/                  # (Generated by download_images.py)
â”‚   â”œâ”€â”€ art_sample_1.jpg
â”‚   â”œâ”€â”€ art_sample_2.jpg
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ index_db/                # (Generated by archive_builder.py)
    â”œâ”€â”€ image_vectors.index  # The FAISS vector database
    â””â”€â”€ metadata.json        # The text data (paths, tags, IDs)
```
